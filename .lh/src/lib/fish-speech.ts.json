{
    "sourceFile": "src/lib/fish-speech.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 2,
            "patches": [
                {
                    "date": 1739014975915,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1739015044975,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,36 +1,24 @@\n-import { spawn } from 'child_process';\n-import path from 'path';\n+import { FishSpeech, type VoiceConfig } from '@fishaudio/fish-speech-node';\n \n-// Remove FishSpeech import and use interface instead\n-interface VoiceConfig {\n-  id: string;\n-  sample: ArrayBuffer | string;\n-}\n-\n class SpeechService {\n+  private fishSpeech: FishSpeech;\n   private currentVoice: VoiceConfig | null = null;\n-  private audioContext: AudioContext | null = null;\n-  private baseUrl: string;\n \n   constructor() {\n-    // Get the base URL from environment variables\n-    this.baseUrl = import.meta.env.VITE_API_URL || '';\n-\n-    // Initialize Web Audio API context on first user interaction\n-    if (typeof window !== 'undefined') {\n-      document.addEventListener('click', () => {\n-        if (!this.audioContext) {\n-          this.audioContext = new AudioContext();\n-        }\n-      }, { once: true });\n-    }\n+    // Initialize Fish Speech with Python backend path\n+    this.fishSpeech = new FishSpeech({\n+      pythonPath: './fish-speech/venv/bin/python',  // Path to Python virtual environment\n+      modelPath: './fish-speech/models',            // Path to downloaded models\n+      deviceType: 'cuda',                          // 'cuda' for GPU, 'cpu' for CPU\n+    });\n   }\n \n   // Set the current voice to use\n   async setVoice(voiceSample: ArrayBuffer | string) {\n     try {\n-      // Store voice configuration\n+      // Load voice model from sample\n+      await this.fishSpeech.loadVoice(voiceSample);\n       this.currentVoice = {\n         id: Date.now().toString(),\n         sample: voiceSample\n       };\n@@ -50,30 +38,16 @@\n       if (!this.currentVoice) {\n         throw new Error('No voice selected');\n       }\n \n-      // Make API call to backend TTS service\n-      const response = await fetch(`${this.baseUrl}/api/tts`, {\n-        method: 'POST',\n-        headers: {\n-          'Content-Type': 'application/json',\n-        },\n-        body: JSON.stringify({\n-          text,\n-          voiceId: this.currentVoice.id,\n-          options: {\n-            speed: options?.speed || 1.0,\n-            pitch: options?.pitch || 1.0,\n-            language: options?.language || 'en'\n-          }\n-        }),\n+      const audio = await this.fishSpeech.synthesize(text, {\n+        speed: options?.speed || 1.0,\n+        pitch: options?.pitch || 1.0,\n+        language: options?.language || 'en',\n+        voiceSample: this.currentVoice.sample\n       });\n \n-      if (!response.ok) {\n-        throw new Error('TTS request failed');\n-      }\n-\n-      return await response.arrayBuffer();\n+      return audio;\n     } catch (error) {\n       console.error('Text to Speech Error:', error);\n       throw error;\n     }\n@@ -81,22 +55,13 @@\n \n   // Speech to Text\n   async speechToText(audioBlob: Blob, language: string = 'en'): Promise<string> {\n     try {\n-      const formData = new FormData();\n-      formData.append('audio', audioBlob);\n-      formData.append('language', language);\n-\n-      const response = await fetch(`${this.baseUrl}/api/stt`, {\n-        method: 'POST',\n-        body: formData,\n+      const audioBuffer = await audioBlob.arrayBuffer();\n+      const text = await this.fishSpeech.recognize(audioBuffer, {\n+        language: language\n       });\n \n-      if (!response.ok) {\n-        throw new Error('STT request failed');\n-      }\n-\n-      const { text } = await response.json();\n       return text;\n     } catch (error) {\n       console.error('Speech to Text Error:', error);\n       throw error;\n@@ -130,16 +95,14 @@\n \n   // Play audio\n   async playAudio(audioBuffer: ArrayBuffer): Promise<AudioBufferSourceNode> {\n     try {\n-      if (!this.audioContext) {\n-        this.audioContext = new AudioContext();\n-      }\n-\n-      const audioSource = this.audioContext.createBufferSource();\n-      const decodedAudio = await this.audioContext.decodeAudioData(audioBuffer);\n+      const audioContext = new AudioContext();\n+      const audioSource = audioContext.createBufferSource();\n+      \n+      const decodedAudio = await audioContext.decodeAudioData(audioBuffer);\n       audioSource.buffer = decodedAudio;\n-      audioSource.connect(this.audioContext.destination);\n+      audioSource.connect(audioContext.destination);\n       \n       audioSource.start(0);\n       return audioSource;\n     } catch (error) {\n@@ -155,27 +118,12 @@\n       const audioBuffer = sampleAudio instanceof Blob \n         ? await sampleAudio.arrayBuffer()\n         : sampleAudio;\n \n-      const formData = new FormData();\n-      formData.append('sample', new Blob([audioBuffer]));\n-\n-      const response = await fetch(`${this.baseUrl}/api/voices/clone`, {\n-        method: 'POST',\n-        body: formData,\n-      });\n-\n-      if (!response.ok) {\n-        throw new Error('Voice cloning failed');\n-      }\n-\n-      const { id } = await response.json();\n-      this.currentVoice = {\n-        id,\n-        sample: audioBuffer\n-      };\n-\n-      return this.currentVoice;\n+      // Process the voice sample\n+      const voiceConfig = await this.fishSpeech.processVoiceSample(audioBuffer);\n+      this.currentVoice = voiceConfig;\n+      return voiceConfig;\n     } catch (error) {\n       console.error('Voice Cloning Error:', error);\n       throw error;\n     }\n"
                },
                {
                    "date": 1739015240062,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,24 +1,36 @@\n-import { FishSpeech, type VoiceConfig } from '@fishaudio/fish-speech-node';\n+import { spawn } from 'child_process';\n+import path from 'path';\n \n+// Remove FishSpeech import and use interface instead\n+interface VoiceConfig {\n+  id: string;\n+  sample: ArrayBuffer | string;\n+}\n+\n class SpeechService {\n-  private fishSpeech: FishSpeech;\n   private currentVoice: VoiceConfig | null = null;\n+  private audioContext: AudioContext | null = null;\n+  private baseUrl: string;\n \n   constructor() {\n-    // Initialize Fish Speech with Python backend path\n-    this.fishSpeech = new FishSpeech({\n-      pythonPath: './fish-speech/venv/bin/python',  // Path to Python virtual environment\n-      modelPath: './fish-speech/models',            // Path to downloaded models\n-      deviceType: 'cuda',                          // 'cuda' for GPU, 'cpu' for CPU\n-    });\n+    // Get the base URL from environment variables\n+    this.baseUrl = import.meta.env.VITE_API_URL || '';\n+\n+    // Initialize Web Audio API context on first user interaction\n+    if (typeof window !== 'undefined') {\n+      document.addEventListener('click', () => {\n+        if (!this.audioContext) {\n+          this.audioContext = new AudioContext();\n+        }\n+      }, { once: true });\n+    }\n   }\n \n   // Set the current voice to use\n   async setVoice(voiceSample: ArrayBuffer | string) {\n     try {\n-      // Load voice model from sample\n-      await this.fishSpeech.loadVoice(voiceSample);\n+      // Store voice configuration\n       this.currentVoice = {\n         id: Date.now().toString(),\n         sample: voiceSample\n       };\n@@ -38,16 +50,30 @@\n       if (!this.currentVoice) {\n         throw new Error('No voice selected');\n       }\n \n-      const audio = await this.fishSpeech.synthesize(text, {\n-        speed: options?.speed || 1.0,\n-        pitch: options?.pitch || 1.0,\n-        language: options?.language || 'en',\n-        voiceSample: this.currentVoice.sample\n+      // Make API call to backend TTS service\n+      const response = await fetch(`${this.baseUrl}/api/tts`, {\n+        method: 'POST',\n+        headers: {\n+          'Content-Type': 'application/json',\n+        },\n+        body: JSON.stringify({\n+          text,\n+          voiceId: this.currentVoice.id,\n+          options: {\n+            speed: options?.speed || 1.0,\n+            pitch: options?.pitch || 1.0,\n+            language: options?.language || 'en'\n+          }\n+        }),\n       });\n \n-      return audio;\n+      if (!response.ok) {\n+        throw new Error('TTS request failed');\n+      }\n+\n+      return await response.arrayBuffer();\n     } catch (error) {\n       console.error('Text to Speech Error:', error);\n       throw error;\n     }\n@@ -55,13 +81,22 @@\n \n   // Speech to Text\n   async speechToText(audioBlob: Blob, language: string = 'en'): Promise<string> {\n     try {\n-      const audioBuffer = await audioBlob.arrayBuffer();\n-      const text = await this.fishSpeech.recognize(audioBuffer, {\n-        language: language\n+      const formData = new FormData();\n+      formData.append('audio', audioBlob);\n+      formData.append('language', language);\n+\n+      const response = await fetch(`${this.baseUrl}/api/stt`, {\n+        method: 'POST',\n+        body: formData,\n       });\n \n+      if (!response.ok) {\n+        throw new Error('STT request failed');\n+      }\n+\n+      const { text } = await response.json();\n       return text;\n     } catch (error) {\n       console.error('Speech to Text Error:', error);\n       throw error;\n@@ -95,14 +130,16 @@\n \n   // Play audio\n   async playAudio(audioBuffer: ArrayBuffer): Promise<AudioBufferSourceNode> {\n     try {\n-      const audioContext = new AudioContext();\n-      const audioSource = audioContext.createBufferSource();\n-      \n-      const decodedAudio = await audioContext.decodeAudioData(audioBuffer);\n+      if (!this.audioContext) {\n+        this.audioContext = new AudioContext();\n+      }\n+\n+      const audioSource = this.audioContext.createBufferSource();\n+      const decodedAudio = await this.audioContext.decodeAudioData(audioBuffer);\n       audioSource.buffer = decodedAudio;\n-      audioSource.connect(audioContext.destination);\n+      audioSource.connect(this.audioContext.destination);\n       \n       audioSource.start(0);\n       return audioSource;\n     } catch (error) {\n@@ -118,12 +155,27 @@\n       const audioBuffer = sampleAudio instanceof Blob \n         ? await sampleAudio.arrayBuffer()\n         : sampleAudio;\n \n-      // Process the voice sample\n-      const voiceConfig = await this.fishSpeech.processVoiceSample(audioBuffer);\n-      this.currentVoice = voiceConfig;\n-      return voiceConfig;\n+      const formData = new FormData();\n+      formData.append('sample', new Blob([audioBuffer]));\n+\n+      const response = await fetch(`${this.baseUrl}/api/voices/clone`, {\n+        method: 'POST',\n+        body: formData,\n+      });\n+\n+      if (!response.ok) {\n+        throw new Error('Voice cloning failed');\n+      }\n+\n+      const { id } = await response.json();\n+      this.currentVoice = {\n+        id,\n+        sample: audioBuffer\n+      };\n+\n+      return this.currentVoice;\n     } catch (error) {\n       console.error('Voice Cloning Error:', error);\n       throw error;\n     }\n"
                }
            ],
            "date": 1739014975915,
            "name": "Commit-0",
            "content": "import { spawn } from 'child_process';\nimport path from 'path';\n\n// Remove FishSpeech import and use interface instead\ninterface VoiceConfig {\n  id: string;\n  sample: ArrayBuffer | string;\n}\n\nclass SpeechService {\n  private currentVoice: VoiceConfig | null = null;\n  private audioContext: AudioContext | null = null;\n  private baseUrl: string;\n\n  constructor() {\n    // Get the base URL from environment variables\n    this.baseUrl = import.meta.env.VITE_API_URL || '';\n\n    // Initialize Web Audio API context on first user interaction\n    if (typeof window !== 'undefined') {\n      document.addEventListener('click', () => {\n        if (!this.audioContext) {\n          this.audioContext = new AudioContext();\n        }\n      }, { once: true });\n    }\n  }\n\n  // Set the current voice to use\n  async setVoice(voiceSample: ArrayBuffer | string) {\n    try {\n      // Store voice configuration\n      this.currentVoice = {\n        id: Date.now().toString(),\n        sample: voiceSample\n      };\n    } catch (error) {\n      console.error('Error setting voice:', error);\n      throw error;\n    }\n  }\n\n  // Text to Speech\n  async textToSpeech(text: string, options?: {\n    speed?: number;\n    pitch?: number;\n    language?: string;\n  }): Promise<ArrayBuffer> {\n    try {\n      if (!this.currentVoice) {\n        throw new Error('No voice selected');\n      }\n\n      // Make API call to backend TTS service\n      const response = await fetch(`${this.baseUrl}/api/tts`, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          text,\n          voiceId: this.currentVoice.id,\n          options: {\n            speed: options?.speed || 1.0,\n            pitch: options?.pitch || 1.0,\n            language: options?.language || 'en'\n          }\n        }),\n      });\n\n      if (!response.ok) {\n        throw new Error('TTS request failed');\n      }\n\n      return await response.arrayBuffer();\n    } catch (error) {\n      console.error('Text to Speech Error:', error);\n      throw error;\n    }\n  }\n\n  // Speech to Text\n  async speechToText(audioBlob: Blob, language: string = 'en'): Promise<string> {\n    try {\n      const formData = new FormData();\n      formData.append('audio', audioBlob);\n      formData.append('language', language);\n\n      const response = await fetch(`${this.baseUrl}/api/stt`, {\n        method: 'POST',\n        body: formData,\n      });\n\n      if (!response.ok) {\n        throw new Error('STT request failed');\n      }\n\n      const { text } = await response.json();\n      return text;\n    } catch (error) {\n      console.error('Speech to Text Error:', error);\n      throw error;\n    }\n  }\n\n  // Start recording\n  async startRecording(onTranscribe?: (text: string) => void): Promise<MediaRecorder> {\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n      const mediaRecorder = new MediaRecorder(stream);\n      const audioChunks: BlobPart[] = [];\n\n      mediaRecorder.ondataavailable = (event) => {\n        audioChunks.push(event.data);\n      };\n\n      mediaRecorder.onstop = async () => {\n        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });\n        const text = await this.speechToText(audioBlob);\n        onTranscribe?.(text);\n      };\n\n      mediaRecorder.start();\n      return mediaRecorder;\n    } catch (error) {\n      console.error('Start Recording Error:', error);\n      throw error;\n    }\n  }\n\n  // Play audio\n  async playAudio(audioBuffer: ArrayBuffer): Promise<AudioBufferSourceNode> {\n    try {\n      if (!this.audioContext) {\n        this.audioContext = new AudioContext();\n      }\n\n      const audioSource = this.audioContext.createBufferSource();\n      const decodedAudio = await this.audioContext.decodeAudioData(audioBuffer);\n      audioSource.buffer = decodedAudio;\n      audioSource.connect(this.audioContext.destination);\n      \n      audioSource.start(0);\n      return audioSource;\n    } catch (error) {\n      console.error('Play Audio Error:', error);\n      throw error;\n    }\n  }\n\n  // Clone voice from sample\n  async cloneVoice(sampleAudio: ArrayBuffer | Blob): Promise<VoiceConfig> {\n    try {\n      // Convert Blob to ArrayBuffer if needed\n      const audioBuffer = sampleAudio instanceof Blob \n        ? await sampleAudio.arrayBuffer()\n        : sampleAudio;\n\n      const formData = new FormData();\n      formData.append('sample', new Blob([audioBuffer]));\n\n      const response = await fetch(`${this.baseUrl}/api/voices/clone`, {\n        method: 'POST',\n        body: formData,\n      });\n\n      if (!response.ok) {\n        throw new Error('Voice cloning failed');\n      }\n\n      const { id } = await response.json();\n      this.currentVoice = {\n        id,\n        sample: audioBuffer\n      };\n\n      return this.currentVoice;\n    } catch (error) {\n      console.error('Voice Cloning Error:', error);\n      throw error;\n    }\n  }\n\n  // Get current voice info\n  getCurrentVoice(): VoiceConfig | null {\n    return this.currentVoice;\n  }\n\n  // Check if a voice is loaded\n  isVoiceLoaded(): boolean {\n    return this.currentVoice !== null;\n  }\n}\n\n// Create a singleton instance\nconst speechService = new SpeechService();\nexport default speechService; "
        }
    ]
}