{
    "sourceFile": "src/lib/fish-speech.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 5,
            "patches": [
                {
                    "date": 1739014975915,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1739015044975,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,36 +1,24 @@\n-import { spawn } from 'child_process';\n-import path from 'path';\n+import { FishSpeech, type VoiceConfig } from '@fishaudio/fish-speech-node';\n \n-// Remove FishSpeech import and use interface instead\n-interface VoiceConfig {\n-  id: string;\n-  sample: ArrayBuffer | string;\n-}\n-\n class SpeechService {\n+  private fishSpeech: FishSpeech;\n   private currentVoice: VoiceConfig | null = null;\n-  private audioContext: AudioContext | null = null;\n-  private baseUrl: string;\n \n   constructor() {\n-    // Get the base URL from environment variables\n-    this.baseUrl = import.meta.env.VITE_API_URL || '';\n-\n-    // Initialize Web Audio API context on first user interaction\n-    if (typeof window !== 'undefined') {\n-      document.addEventListener('click', () => {\n-        if (!this.audioContext) {\n-          this.audioContext = new AudioContext();\n-        }\n-      }, { once: true });\n-    }\n+    // Initialize Fish Speech with Python backend path\n+    this.fishSpeech = new FishSpeech({\n+      pythonPath: './fish-speech/venv/bin/python',  // Path to Python virtual environment\n+      modelPath: './fish-speech/models',            // Path to downloaded models\n+      deviceType: 'cuda',                          // 'cuda' for GPU, 'cpu' for CPU\n+    });\n   }\n \n   // Set the current voice to use\n   async setVoice(voiceSample: ArrayBuffer | string) {\n     try {\n-      // Store voice configuration\n+      // Load voice model from sample\n+      await this.fishSpeech.loadVoice(voiceSample);\n       this.currentVoice = {\n         id: Date.now().toString(),\n         sample: voiceSample\n       };\n@@ -50,30 +38,16 @@\n       if (!this.currentVoice) {\n         throw new Error('No voice selected');\n       }\n \n-      // Make API call to backend TTS service\n-      const response = await fetch(`${this.baseUrl}/api/tts`, {\n-        method: 'POST',\n-        headers: {\n-          'Content-Type': 'application/json',\n-        },\n-        body: JSON.stringify({\n-          text,\n-          voiceId: this.currentVoice.id,\n-          options: {\n-            speed: options?.speed || 1.0,\n-            pitch: options?.pitch || 1.0,\n-            language: options?.language || 'en'\n-          }\n-        }),\n+      const audio = await this.fishSpeech.synthesize(text, {\n+        speed: options?.speed || 1.0,\n+        pitch: options?.pitch || 1.0,\n+        language: options?.language || 'en',\n+        voiceSample: this.currentVoice.sample\n       });\n \n-      if (!response.ok) {\n-        throw new Error('TTS request failed');\n-      }\n-\n-      return await response.arrayBuffer();\n+      return audio;\n     } catch (error) {\n       console.error('Text to Speech Error:', error);\n       throw error;\n     }\n@@ -81,22 +55,13 @@\n \n   // Speech to Text\n   async speechToText(audioBlob: Blob, language: string = 'en'): Promise<string> {\n     try {\n-      const formData = new FormData();\n-      formData.append('audio', audioBlob);\n-      formData.append('language', language);\n-\n-      const response = await fetch(`${this.baseUrl}/api/stt`, {\n-        method: 'POST',\n-        body: formData,\n+      const audioBuffer = await audioBlob.arrayBuffer();\n+      const text = await this.fishSpeech.recognize(audioBuffer, {\n+        language: language\n       });\n \n-      if (!response.ok) {\n-        throw new Error('STT request failed');\n-      }\n-\n-      const { text } = await response.json();\n       return text;\n     } catch (error) {\n       console.error('Speech to Text Error:', error);\n       throw error;\n@@ -130,16 +95,14 @@\n \n   // Play audio\n   async playAudio(audioBuffer: ArrayBuffer): Promise<AudioBufferSourceNode> {\n     try {\n-      if (!this.audioContext) {\n-        this.audioContext = new AudioContext();\n-      }\n-\n-      const audioSource = this.audioContext.createBufferSource();\n-      const decodedAudio = await this.audioContext.decodeAudioData(audioBuffer);\n+      const audioContext = new AudioContext();\n+      const audioSource = audioContext.createBufferSource();\n+      \n+      const decodedAudio = await audioContext.decodeAudioData(audioBuffer);\n       audioSource.buffer = decodedAudio;\n-      audioSource.connect(this.audioContext.destination);\n+      audioSource.connect(audioContext.destination);\n       \n       audioSource.start(0);\n       return audioSource;\n     } catch (error) {\n@@ -155,27 +118,12 @@\n       const audioBuffer = sampleAudio instanceof Blob \n         ? await sampleAudio.arrayBuffer()\n         : sampleAudio;\n \n-      const formData = new FormData();\n-      formData.append('sample', new Blob([audioBuffer]));\n-\n-      const response = await fetch(`${this.baseUrl}/api/voices/clone`, {\n-        method: 'POST',\n-        body: formData,\n-      });\n-\n-      if (!response.ok) {\n-        throw new Error('Voice cloning failed');\n-      }\n-\n-      const { id } = await response.json();\n-      this.currentVoice = {\n-        id,\n-        sample: audioBuffer\n-      };\n-\n-      return this.currentVoice;\n+      // Process the voice sample\n+      const voiceConfig = await this.fishSpeech.processVoiceSample(audioBuffer);\n+      this.currentVoice = voiceConfig;\n+      return voiceConfig;\n     } catch (error) {\n       console.error('Voice Cloning Error:', error);\n       throw error;\n     }\n"
                },
                {
                    "date": 1739015240062,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,24 +1,36 @@\n-import { FishSpeech, type VoiceConfig } from '@fishaudio/fish-speech-node';\n+import { spawn } from 'child_process';\n+import path from 'path';\n \n+// Remove FishSpeech import and use interface instead\n+interface VoiceConfig {\n+  id: string;\n+  sample: ArrayBuffer | string;\n+}\n+\n class SpeechService {\n-  private fishSpeech: FishSpeech;\n   private currentVoice: VoiceConfig | null = null;\n+  private audioContext: AudioContext | null = null;\n+  private baseUrl: string;\n \n   constructor() {\n-    // Initialize Fish Speech with Python backend path\n-    this.fishSpeech = new FishSpeech({\n-      pythonPath: './fish-speech/venv/bin/python',  // Path to Python virtual environment\n-      modelPath: './fish-speech/models',            // Path to downloaded models\n-      deviceType: 'cuda',                          // 'cuda' for GPU, 'cpu' for CPU\n-    });\n+    // Get the base URL from environment variables\n+    this.baseUrl = import.meta.env.VITE_API_URL || '';\n+\n+    // Initialize Web Audio API context on first user interaction\n+    if (typeof window !== 'undefined') {\n+      document.addEventListener('click', () => {\n+        if (!this.audioContext) {\n+          this.audioContext = new AudioContext();\n+        }\n+      }, { once: true });\n+    }\n   }\n \n   // Set the current voice to use\n   async setVoice(voiceSample: ArrayBuffer | string) {\n     try {\n-      // Load voice model from sample\n-      await this.fishSpeech.loadVoice(voiceSample);\n+      // Store voice configuration\n       this.currentVoice = {\n         id: Date.now().toString(),\n         sample: voiceSample\n       };\n@@ -38,16 +50,30 @@\n       if (!this.currentVoice) {\n         throw new Error('No voice selected');\n       }\n \n-      const audio = await this.fishSpeech.synthesize(text, {\n-        speed: options?.speed || 1.0,\n-        pitch: options?.pitch || 1.0,\n-        language: options?.language || 'en',\n-        voiceSample: this.currentVoice.sample\n+      // Make API call to backend TTS service\n+      const response = await fetch(`${this.baseUrl}/api/tts`, {\n+        method: 'POST',\n+        headers: {\n+          'Content-Type': 'application/json',\n+        },\n+        body: JSON.stringify({\n+          text,\n+          voiceId: this.currentVoice.id,\n+          options: {\n+            speed: options?.speed || 1.0,\n+            pitch: options?.pitch || 1.0,\n+            language: options?.language || 'en'\n+          }\n+        }),\n       });\n \n-      return audio;\n+      if (!response.ok) {\n+        throw new Error('TTS request failed');\n+      }\n+\n+      return await response.arrayBuffer();\n     } catch (error) {\n       console.error('Text to Speech Error:', error);\n       throw error;\n     }\n@@ -55,13 +81,22 @@\n \n   // Speech to Text\n   async speechToText(audioBlob: Blob, language: string = 'en'): Promise<string> {\n     try {\n-      const audioBuffer = await audioBlob.arrayBuffer();\n-      const text = await this.fishSpeech.recognize(audioBuffer, {\n-        language: language\n+      const formData = new FormData();\n+      formData.append('audio', audioBlob);\n+      formData.append('language', language);\n+\n+      const response = await fetch(`${this.baseUrl}/api/stt`, {\n+        method: 'POST',\n+        body: formData,\n       });\n \n+      if (!response.ok) {\n+        throw new Error('STT request failed');\n+      }\n+\n+      const { text } = await response.json();\n       return text;\n     } catch (error) {\n       console.error('Speech to Text Error:', error);\n       throw error;\n@@ -95,14 +130,16 @@\n \n   // Play audio\n   async playAudio(audioBuffer: ArrayBuffer): Promise<AudioBufferSourceNode> {\n     try {\n-      const audioContext = new AudioContext();\n-      const audioSource = audioContext.createBufferSource();\n-      \n-      const decodedAudio = await audioContext.decodeAudioData(audioBuffer);\n+      if (!this.audioContext) {\n+        this.audioContext = new AudioContext();\n+      }\n+\n+      const audioSource = this.audioContext.createBufferSource();\n+      const decodedAudio = await this.audioContext.decodeAudioData(audioBuffer);\n       audioSource.buffer = decodedAudio;\n-      audioSource.connect(audioContext.destination);\n+      audioSource.connect(this.audioContext.destination);\n       \n       audioSource.start(0);\n       return audioSource;\n     } catch (error) {\n@@ -118,12 +155,27 @@\n       const audioBuffer = sampleAudio instanceof Blob \n         ? await sampleAudio.arrayBuffer()\n         : sampleAudio;\n \n-      // Process the voice sample\n-      const voiceConfig = await this.fishSpeech.processVoiceSample(audioBuffer);\n-      this.currentVoice = voiceConfig;\n-      return voiceConfig;\n+      const formData = new FormData();\n+      formData.append('sample', new Blob([audioBuffer]));\n+\n+      const response = await fetch(`${this.baseUrl}/api/voices/clone`, {\n+        method: 'POST',\n+        body: formData,\n+      });\n+\n+      if (!response.ok) {\n+        throw new Error('Voice cloning failed');\n+      }\n+\n+      const { id } = await response.json();\n+      this.currentVoice = {\n+        id,\n+        sample: audioBuffer\n+      };\n+\n+      return this.currentVoice;\n     } catch (error) {\n       console.error('Voice Cloning Error:', error);\n       throw error;\n     }\n"
                },
                {
                    "date": 1740899179543,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,197 +1,197 @@\n-import { spawn } from 'child_process';\n-import path from 'path';\n-\n-// Remove FishSpeech import and use interface instead\n-interface VoiceConfig {\n-  id: string;\n-  sample: ArrayBuffer | string;\n-}\n-\n-class SpeechService {\n-  private currentVoice: VoiceConfig | null = null;\n-  private audioContext: AudioContext | null = null;\n-  private baseUrl: string;\n-\n-  constructor() {\n-    // Get the base URL from environment variables\n-    this.baseUrl = import.meta.env.VITE_API_URL || '';\n-\n-    // Initialize Web Audio API context on first user interaction\n-    if (typeof window !== 'undefined') {\n-      document.addEventListener('click', () => {\n-        if (!this.audioContext) {\n-          this.audioContext = new AudioContext();\n-        }\n-      }, { once: true });\n-    }\n-  }\n-\n-  // Set the current voice to use\n-  async setVoice(voiceSample: ArrayBuffer | string) {\n-    try {\n-      // Store voice configuration\n-      this.currentVoice = {\n-        id: Date.now().toString(),\n-        sample: voiceSample\n-      };\n-    } catch (error) {\n-      console.error('Error setting voice:', error);\n-      throw error;\n-    }\n-  }\n-\n-  // Text to Speech\n-  async textToSpeech(text: string, options?: {\n-    speed?: number;\n-    pitch?: number;\n-    language?: string;\n-  }): Promise<ArrayBuffer> {\n-    try {\n-      if (!this.currentVoice) {\n-        throw new Error('No voice selected');\n-      }\n-\n-      // Make API call to backend TTS service\n-      const response = await fetch(`${this.baseUrl}/api/tts`, {\n-        method: 'POST',\n-        headers: {\n-          'Content-Type': 'application/json',\n-        },\n-        body: JSON.stringify({\n-          text,\n-          voiceId: this.currentVoice.id,\n-          options: {\n-            speed: options?.speed || 1.0,\n-            pitch: options?.pitch || 1.0,\n-            language: options?.language || 'en'\n-          }\n-        }),\n-      });\n-\n-      if (!response.ok) {\n-        throw new Error('TTS request failed');\n-      }\n-\n-      return await response.arrayBuffer();\n-    } catch (error) {\n-      console.error('Text to Speech Error:', error);\n-      throw error;\n-    }\n-  }\n-\n-  // Speech to Text\n-  async speechToText(audioBlob: Blob, language: string = 'en'): Promise<string> {\n-    try {\n-      const formData = new FormData();\n-      formData.append('audio', audioBlob);\n-      formData.append('language', language);\n-\n-      const response = await fetch(`${this.baseUrl}/api/stt`, {\n-        method: 'POST',\n-        body: formData,\n-      });\n-\n-      if (!response.ok) {\n-        throw new Error('STT request failed');\n-      }\n-\n-      const { text } = await response.json();\n-      return text;\n-    } catch (error) {\n-      console.error('Speech to Text Error:', error);\n-      throw error;\n-    }\n-  }\n-\n-  // Start recording\n-  async startRecording(onTranscribe?: (text: string) => void): Promise<MediaRecorder> {\n-    try {\n-      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n-      const mediaRecorder = new MediaRecorder(stream);\n-      const audioChunks: BlobPart[] = [];\n-\n-      mediaRecorder.ondataavailable = (event) => {\n-        audioChunks.push(event.data);\n-      };\n-\n-      mediaRecorder.onstop = async () => {\n-        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });\n-        const text = await this.speechToText(audioBlob);\n-        onTranscribe?.(text);\n-      };\n-\n-      mediaRecorder.start();\n-      return mediaRecorder;\n-    } catch (error) {\n-      console.error('Start Recording Error:', error);\n-      throw error;\n-    }\n-  }\n-\n-  // Play audio\n-  async playAudio(audioBuffer: ArrayBuffer): Promise<AudioBufferSourceNode> {\n-    try {\n-      if (!this.audioContext) {\n-        this.audioContext = new AudioContext();\n-      }\n-\n-      const audioSource = this.audioContext.createBufferSource();\n-      const decodedAudio = await this.audioContext.decodeAudioData(audioBuffer);\n-      audioSource.buffer = decodedAudio;\n-      audioSource.connect(this.audioContext.destination);\n-      \n-      audioSource.start(0);\n-      return audioSource;\n-    } catch (error) {\n-      console.error('Play Audio Error:', error);\n-      throw error;\n-    }\n-  }\n-\n-  // Clone voice from sample\n-  async cloneVoice(sampleAudio: ArrayBuffer | Blob): Promise<VoiceConfig> {\n-    try {\n-      // Convert Blob to ArrayBuffer if needed\n-      const audioBuffer = sampleAudio instanceof Blob \n-        ? await sampleAudio.arrayBuffer()\n-        : sampleAudio;\n-\n-      const formData = new FormData();\n-      formData.append('sample', new Blob([audioBuffer]));\n-\n-      const response = await fetch(`${this.baseUrl}/api/voices/clone`, {\n-        method: 'POST',\n-        body: formData,\n-      });\n-\n-      if (!response.ok) {\n-        throw new Error('Voice cloning failed');\n-      }\n-\n-      const { id } = await response.json();\n-      this.currentVoice = {\n-        id,\n-        sample: audioBuffer\n-      };\n-\n-      return this.currentVoice;\n-    } catch (error) {\n-      console.error('Voice Cloning Error:', error);\n-      throw error;\n-    }\n-  }\n-\n-  // Get current voice info\n-  getCurrentVoice(): VoiceConfig | null {\n-    return this.currentVoice;\n-  }\n-\n-  // Check if a voice is loaded\n-  isVoiceLoaded(): boolean {\n-    return this.currentVoice !== null;\n-  }\n-}\n-\n-// Create a singleton instance\n-const speechService = new SpeechService();\n+// import { spawn } from 'child_process';\r\n+// import path from 'path';\r\n+\r\n+// Remove FishSpeech import and use interface instead\r\n+interface VoiceConfig {\r\n+  id: string;\r\n+  sample: ArrayBuffer | string;\r\n+}\r\n+\r\n+class SpeechService {\r\n+  private currentVoice: VoiceConfig | null = null;\r\n+  private audioContext: AudioContext | null = null;\r\n+  private baseUrl: string;\r\n+\r\n+  constructor() {\r\n+    // Get the base URL from environment variables\r\n+    this.baseUrl = import.meta.env.VITE_API_URL || '';\r\n+\r\n+    // Initialize Web Audio API context on first user interaction\r\n+    if (typeof window !== 'undefined') {\r\n+      document.addEventListener('click', () => {\r\n+        if (!this.audioContext) {\r\n+          this.audioContext = new AudioContext();\r\n+        }\r\n+      }, { once: true });\r\n+    }\r\n+  }\r\n+\r\n+  // Set the current voice to use\r\n+  async setVoice(voiceSample: ArrayBuffer | string) {\r\n+    try {\r\n+      // Store voice configuration\r\n+      this.currentVoice = {\r\n+        id: Date.now().toString(),\r\n+        sample: voiceSample\r\n+      };\r\n+    } catch (error) {\r\n+      console.error('Error setting voice:', error);\r\n+      throw error;\r\n+    }\r\n+  }\r\n+\r\n+  // Text to Speech\r\n+  async textToSpeech(text: string, options?: {\r\n+    speed?: number;\r\n+    pitch?: number;\r\n+    language?: string;\r\n+  }): Promise<ArrayBuffer> {\r\n+    try {\r\n+      if (!this.currentVoice) {\r\n+        throw new Error('No voice selected');\r\n+      }\r\n+\r\n+      // Make API call to backend TTS service\r\n+      const response = await fetch(`${this.baseUrl}/api/tts`, {\r\n+        method: 'POST',\r\n+        headers: {\r\n+          'Content-Type': 'application/json',\r\n+        },\r\n+        body: JSON.stringify({\r\n+          text,\r\n+          voiceId: this.currentVoice.id,\r\n+          options: {\r\n+            speed: options?.speed || 1.0,\r\n+            pitch: options?.pitch || 1.0,\r\n+            language: options?.language || 'en'\r\n+          }\r\n+        }),\r\n+      });\r\n+\r\n+      if (!response.ok) {\r\n+        throw new Error('TTS request failed');\r\n+      }\r\n+\r\n+      return await response.arrayBuffer();\r\n+    } catch (error) {\r\n+      console.error('Text to Speech Error:', error);\r\n+      throw error;\r\n+    }\r\n+  }\r\n+\r\n+  // Speech to Text\r\n+  async speechToText(audioBlob: Blob, language: string = 'en'): Promise<string> {\r\n+    try {\r\n+      const formData = new FormData();\r\n+      formData.append('audio', audioBlob);\r\n+      formData.append('language', language);\r\n+\r\n+      const response = await fetch(`${this.baseUrl}/api/stt`, {\r\n+        method: 'POST',\r\n+        body: formData,\r\n+      });\r\n+\r\n+      if (!response.ok) {\r\n+        throw new Error('STT request failed');\r\n+      }\r\n+\r\n+      const { text } = await response.json();\r\n+      return text;\r\n+    } catch (error) {\r\n+      console.error('Speech to Text Error:', error);\r\n+      throw error;\r\n+    }\r\n+  }\r\n+\r\n+  // Start recording\r\n+  async startRecording(onTranscribe?: (text: string) => void): Promise<MediaRecorder> {\r\n+    try {\r\n+      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\r\n+      const mediaRecorder = new MediaRecorder(stream);\r\n+      const audioChunks: BlobPart[] = [];\r\n+\r\n+      mediaRecorder.ondataavailable = (event) => {\r\n+        audioChunks.push(event.data);\r\n+      };\r\n+\r\n+      mediaRecorder.onstop = async () => {\r\n+        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });\r\n+        const text = await this.speechToText(audioBlob);\r\n+        onTranscribe?.(text);\r\n+      };\r\n+\r\n+      mediaRecorder.start();\r\n+      return mediaRecorder;\r\n+    } catch (error) {\r\n+      console.error('Start Recording Error:', error);\r\n+      throw error;\r\n+    }\r\n+  }\r\n+\r\n+  // Play audio\r\n+  async playAudio(audioBuffer: ArrayBuffer): Promise<AudioBufferSourceNode> {\r\n+    try {\r\n+      if (!this.audioContext) {\r\n+        this.audioContext = new AudioContext();\r\n+      }\r\n+\r\n+      const audioSource = this.audioContext.createBufferSource();\r\n+      const decodedAudio = await this.audioContext.decodeAudioData(audioBuffer);\r\n+      audioSource.buffer = decodedAudio;\r\n+      audioSource.connect(this.audioContext.destination);\r\n+      \r\n+      audioSource.start(0);\r\n+      return audioSource;\r\n+    } catch (error) {\r\n+      console.error('Play Audio Error:', error);\r\n+      throw error;\r\n+    }\r\n+  }\r\n+\r\n+  // Clone voice from sample\r\n+  async cloneVoice(sampleAudio: ArrayBuffer | Blob): Promise<VoiceConfig> {\r\n+    try {\r\n+      // Convert Blob to ArrayBuffer if needed\r\n+      const audioBuffer = sampleAudio instanceof Blob \r\n+        ? await sampleAudio.arrayBuffer()\r\n+        : sampleAudio;\r\n+\r\n+      const formData = new FormData();\r\n+      formData.append('sample', new Blob([audioBuffer]));\r\n+\r\n+      const response = await fetch(`${this.baseUrl}/api/voices/clone`, {\r\n+        method: 'POST',\r\n+        body: formData,\r\n+      });\r\n+\r\n+      if (!response.ok) {\r\n+        throw new Error('Voice cloning failed');\r\n+      }\r\n+\r\n+      const { id } = await response.json();\r\n+      this.currentVoice = {\r\n+        id,\r\n+        sample: audioBuffer\r\n+      };\r\n+\r\n+      return this.currentVoice;\r\n+    } catch (error) {\r\n+      console.error('Voice Cloning Error:', error);\r\n+      throw error;\r\n+    }\r\n+  }\r\n+\r\n+  // Get current voice info\r\n+  getCurrentVoice(): VoiceConfig | null {\r\n+    return this.currentVoice;\r\n+  }\r\n+\r\n+  // Check if a voice is loaded\r\n+  isVoiceLoaded(): boolean {\r\n+    return this.currentVoice !== null;\r\n+  }\r\n+}\r\n+\r\n+// Create a singleton instance\r\n+const speechService = new SpeechService();\r\n export default speechService; \n\\ No newline at end of file\n"
                },
                {
                    "date": 1741214199703,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,10 +12,10 @@\n   private audioContext: AudioContext | null = null;\r\n   private baseUrl: string;\r\n \r\n   constructor() {\r\n-    // Get the base URL from environment variables\r\n-    this.baseUrl = import.meta.env.VITE_API_URL || '';\r\n+    // Get the base URL from environment variables or default to current origin\r\n+    this.baseUrl = import.meta.env.VITE_API_URL || window.location.origin;\r\n \r\n     // Initialize Web Audio API context on first user interaction\r\n     if (typeof window !== 'undefined') {\r\n       document.addEventListener('click', () => {\r\n@@ -25,8 +25,13 @@\n       }, { once: true });\r\n     }\r\n   }\r\n \r\n+  // Method to get the audio context\r\n+  getAudioContext(): AudioContext | null {\r\n+    return this.audioContext;\r\n+  }\r\n+\r\n   // Set the current voice to use\r\n   async setVoice(voiceSample: ArrayBuffer | string) {\r\n     try {\r\n       // Store voice configuration\r\n@@ -47,13 +52,21 @@\n     language?: string;\r\n   }): Promise<ArrayBuffer> {\r\n     try {\r\n       if (!this.currentVoice) {\r\n-        throw new Error('No voice selected');\r\n+        // If no voice is selected, create a default voice ID\r\n+        this.currentVoice = {\r\n+          id: 'default',\r\n+          sample: new ArrayBuffer(0)\r\n+        };\r\n       }\r\n \r\n       // Make API call to backend TTS service\r\n-      const response = await fetch(`${this.baseUrl}/api/tts`, {\r\n+      // Fix the endpoint path to ensure it's correct\r\n+      const endpoint = `${this.baseUrl}/api/tts`;\r\n+      console.log(`Making TTS request to: ${endpoint}`);\r\n+      \r\n+      const response = await fetch(endpoint, {\r\n         method: 'POST',\r\n         headers: {\r\n           'Content-Type': 'application/json',\r\n         },\r\n"
                },
                {
                    "date": 1746696272467,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,7 +1,8 @@\n // import { spawn } from 'child_process';\r\n // import path from 'path';\r\n \r\n+import { LocalCache, MemoryCache, CACHE_KEYS, CACHE_TTL } from './cache';\r\n // Remove FishSpeech import and use interface instead\r\n interface VoiceConfig {\r\n   id: string;\r\n   sample: ArrayBuffer | string;\r\n"
                }
            ],
            "date": 1739014975915,
            "name": "Commit-0",
            "content": "import { spawn } from 'child_process';\nimport path from 'path';\n\n// Remove FishSpeech import and use interface instead\ninterface VoiceConfig {\n  id: string;\n  sample: ArrayBuffer | string;\n}\n\nclass SpeechService {\n  private currentVoice: VoiceConfig | null = null;\n  private audioContext: AudioContext | null = null;\n  private baseUrl: string;\n\n  constructor() {\n    // Get the base URL from environment variables\n    this.baseUrl = import.meta.env.VITE_API_URL || '';\n\n    // Initialize Web Audio API context on first user interaction\n    if (typeof window !== 'undefined') {\n      document.addEventListener('click', () => {\n        if (!this.audioContext) {\n          this.audioContext = new AudioContext();\n        }\n      }, { once: true });\n    }\n  }\n\n  // Set the current voice to use\n  async setVoice(voiceSample: ArrayBuffer | string) {\n    try {\n      // Store voice configuration\n      this.currentVoice = {\n        id: Date.now().toString(),\n        sample: voiceSample\n      };\n    } catch (error) {\n      console.error('Error setting voice:', error);\n      throw error;\n    }\n  }\n\n  // Text to Speech\n  async textToSpeech(text: string, options?: {\n    speed?: number;\n    pitch?: number;\n    language?: string;\n  }): Promise<ArrayBuffer> {\n    try {\n      if (!this.currentVoice) {\n        throw new Error('No voice selected');\n      }\n\n      // Make API call to backend TTS service\n      const response = await fetch(`${this.baseUrl}/api/tts`, {\n        method: 'POST',\n        headers: {\n          'Content-Type': 'application/json',\n        },\n        body: JSON.stringify({\n          text,\n          voiceId: this.currentVoice.id,\n          options: {\n            speed: options?.speed || 1.0,\n            pitch: options?.pitch || 1.0,\n            language: options?.language || 'en'\n          }\n        }),\n      });\n\n      if (!response.ok) {\n        throw new Error('TTS request failed');\n      }\n\n      return await response.arrayBuffer();\n    } catch (error) {\n      console.error('Text to Speech Error:', error);\n      throw error;\n    }\n  }\n\n  // Speech to Text\n  async speechToText(audioBlob: Blob, language: string = 'en'): Promise<string> {\n    try {\n      const formData = new FormData();\n      formData.append('audio', audioBlob);\n      formData.append('language', language);\n\n      const response = await fetch(`${this.baseUrl}/api/stt`, {\n        method: 'POST',\n        body: formData,\n      });\n\n      if (!response.ok) {\n        throw new Error('STT request failed');\n      }\n\n      const { text } = await response.json();\n      return text;\n    } catch (error) {\n      console.error('Speech to Text Error:', error);\n      throw error;\n    }\n  }\n\n  // Start recording\n  async startRecording(onTranscribe?: (text: string) => void): Promise<MediaRecorder> {\n    try {\n      const stream = await navigator.mediaDevices.getUserMedia({ audio: true });\n      const mediaRecorder = new MediaRecorder(stream);\n      const audioChunks: BlobPart[] = [];\n\n      mediaRecorder.ondataavailable = (event) => {\n        audioChunks.push(event.data);\n      };\n\n      mediaRecorder.onstop = async () => {\n        const audioBlob = new Blob(audioChunks, { type: 'audio/wav' });\n        const text = await this.speechToText(audioBlob);\n        onTranscribe?.(text);\n      };\n\n      mediaRecorder.start();\n      return mediaRecorder;\n    } catch (error) {\n      console.error('Start Recording Error:', error);\n      throw error;\n    }\n  }\n\n  // Play audio\n  async playAudio(audioBuffer: ArrayBuffer): Promise<AudioBufferSourceNode> {\n    try {\n      if (!this.audioContext) {\n        this.audioContext = new AudioContext();\n      }\n\n      const audioSource = this.audioContext.createBufferSource();\n      const decodedAudio = await this.audioContext.decodeAudioData(audioBuffer);\n      audioSource.buffer = decodedAudio;\n      audioSource.connect(this.audioContext.destination);\n      \n      audioSource.start(0);\n      return audioSource;\n    } catch (error) {\n      console.error('Play Audio Error:', error);\n      throw error;\n    }\n  }\n\n  // Clone voice from sample\n  async cloneVoice(sampleAudio: ArrayBuffer | Blob): Promise<VoiceConfig> {\n    try {\n      // Convert Blob to ArrayBuffer if needed\n      const audioBuffer = sampleAudio instanceof Blob \n        ? await sampleAudio.arrayBuffer()\n        : sampleAudio;\n\n      const formData = new FormData();\n      formData.append('sample', new Blob([audioBuffer]));\n\n      const response = await fetch(`${this.baseUrl}/api/voices/clone`, {\n        method: 'POST',\n        body: formData,\n      });\n\n      if (!response.ok) {\n        throw new Error('Voice cloning failed');\n      }\n\n      const { id } = await response.json();\n      this.currentVoice = {\n        id,\n        sample: audioBuffer\n      };\n\n      return this.currentVoice;\n    } catch (error) {\n      console.error('Voice Cloning Error:', error);\n      throw error;\n    }\n  }\n\n  // Get current voice info\n  getCurrentVoice(): VoiceConfig | null {\n    return this.currentVoice;\n  }\n\n  // Check if a voice is loaded\n  isVoiceLoaded(): boolean {\n    return this.currentVoice !== null;\n  }\n}\n\n// Create a singleton instance\nconst speechService = new SpeechService();\nexport default speechService; "
        }
    ]
}