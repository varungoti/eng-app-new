{
    "sourceFile": "src/lib/api.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 11,
            "patches": [
                {
                    "date": 1739013790585,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1739013841137,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -19,8 +19,12 @@\n \r\n export const api = {\r\n   async get<T>(path: string, options: { where?: any; include?: any; orderBy?: any } = {}): Promise<T[]> {\r\n     const loadId = `GET_${path}_${Date.now()}`;\r\n+    await dataFlowMonitor.trackDataLoad(loadId, { \r\n+      source: path,\r\n+      recordCount: 0 // Will be updated when data is received\r\n+    });\r\n     const cacheKey = `${path}-${JSON.stringify(options)}`;\r\n     \r\n     const opId = dataFlowMonitor.startOperation('query', `GET ${path}`, { options });\r\n     try {\r\n"
                },
                {
                    "date": 1739013877586,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,14 +25,12 @@\n       recordCount: 0 // Will be updated when data is received\r\n     });\r\n     const cacheKey = `${path}-${JSON.stringify(options)}`;\r\n     \r\n-    const opId = dataFlowMonitor.startOperation('query', `GET ${path}`, { options });\r\n     try {\r\n       // Try cache first\r\n       const cachedData = cache.get(cacheKey);\r\n       if (cachedData) {\r\n-        dataFlowMonitor.endOperation(opId);\r\n         return cachedData;\r\n       }\r\n \r\n       const query = supabase\r\n"
                },
                {
                    "date": 1739013883872,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,12 +25,14 @@\n       recordCount: 0 // Will be updated when data is received\r\n     });\r\n     const cacheKey = `${path}-${JSON.stringify(options)}`;\r\n     \r\n+    const opId = dataFlowMonitor.startOperation('query', `GET ${path}`, { options });\r\n     try {\r\n       // Try cache first\r\n       const cachedData = cache.get(cacheKey);\r\n       if (cachedData) {\r\n+        dataFlowMonitor.endOperation(opId);\r\n         return cachedData;\r\n       }\r\n \r\n       const query = supabase\r\n"
                },
                {
                    "date": 1739014323580,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n import { supabase } from './supabase';\r\n import { logger } from './logger';\r\n import { DataCache } from './cache';\r\n-import { dataFlowMonitor } from './monitoring/instance';\r\n+import { dataFlowMonitor } from './monitoring/DataFlowMonitor';\r\n \r\n export class APIError extends Error {\r\n   constructor(message: string, public statusCode: number) {\r\n     super(message);\r\n"
                },
                {
                    "date": 1739015150901,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n import { supabase } from './supabase';\r\n import { logger } from './logger';\r\n import { DataCache } from './cache';\r\n-import { dataFlowMonitor } from './monitoring/DataFlowMonitor';\r\n+import { dataFlowMonitor } from './monitoring/instance';\r\n \r\n export class APIError extends Error {\r\n   constructor(message: string, public statusCode: number) {\r\n     super(message);\r\n"
                },
                {
                    "date": 1739015183755,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -84,14 +84,12 @@\n       cache.clear();\r\n \r\n       return result as T;\r\n     } catch (err) {\r\n-      logger.error(`Failed to create ${path}`, {\r\n-        context: { error: err, data },\r\n-        source: 'api.post'\r\n-      });\r\n+      logger.error(`Failed to create ${path}`, 'api.post', err);\r\n       throw new APIError(`Failed to create ${path}`, 500);\r\n     }\r\n+\r\n   },\r\n \r\n   async put<T>(path: string, id: string, data: any): Promise<T> {\r\n     try {\r\n@@ -108,14 +106,12 @@\n       cache.clear();\r\n \r\n       return result as T;\r\n     } catch (err) {\r\n-      logger.error(`Failed to update ${path}`, {\r\n-        context: { error: err, id, data },\r\n-        source: 'api.put'\r\n-      });\r\n+      logger.error(`Failed to update ${path}`, 'api.put', err);\r\n       throw new APIError(`Failed to update ${path}`, 500);\r\n     }\r\n+\r\n   },\r\n \r\n   async delete(path: string, id: string): Promise<boolean> {\r\n     try {\r\n@@ -130,13 +126,11 @@\n       cache.clear();\r\n \r\n       return true;\r\n     } catch (err) {\r\n-      logger.error(`Failed to delete ${path}`, {\r\n-        context: { error: err, id },\r\n-        source: 'api.delete'\r\n-      });\r\n+      logger.error(`Failed to delete ${path}`, 'api.delete', err);\r\n       throw new APIError(`Failed to delete ${path}`, 500);\r\n+\r\n     }\r\n   },\r\n \r\n   // Batch operations with transaction support\r\n@@ -145,22 +139,18 @@\n       const results = await Promise.allSettled(operations.map(op => op()));\r\n       \r\n       const failures = results.filter(r => r.status === 'rejected');\r\n       if (failures.length > 0) {\r\n-        logger.error('Batch operation partially failed', {\r\n-          context: { failures },\r\n-          source: 'api.batch'\r\n-        });\r\n+        logger.error('Batch operation partially failed', 'api.batch', failures);\r\n+\r\n       }\r\n \r\n       return results\r\n         .filter((r): r is PromiseFulfilledResult<Awaited<T>> => r.status === 'fulfilled')\r\n         .map(r => r.value);\r\n     } catch (err) {\r\n-      logger.error('Batch operation failed', {\r\n-        context: { error: err },\r\n-        source: 'api.batch'\r\n-      });\r\n+      logger.error('Batch operation failed', 'api.batch', err);\r\n       throw new APIError('Batch operation failed', 500);\r\n+\r\n     }\r\n   }\r\n };\n\\ No newline at end of file\n"
                },
                {
                    "date": 1740852792058,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,9 +12,9 @@\n \r\n const cache = DataCache.getInstance();\r\n \r\n const handleQueryError = (error: any, path: string) => {\r\n-  logger.error(`Failed to fetch ${path}: ${error}`, 'api.get');\r\n+  logger.error(`Failed to fetch ${path}: ${error}`, { source: 'api.get' });\r\n   throw new APIError(`Failed to fetch ${path}`, 500);\r\n };\r\n \r\n export const api = {\r\n"
                },
                {
                    "date": 1740852805425,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -12,9 +12,9 @@\n \r\n const cache = DataCache.getInstance();\r\n \r\n const handleQueryError = (error: any, path: string) => {\r\n-  logger.error(`Failed to fetch ${path}: ${error}`, { source: 'api.get' });\r\n+  logger.error(`Failed to fetch ${path}: ${error}`, { source: 'api.get' } );\r\n   throw new APIError(`Failed to fetch ${path}`, 500);\r\n };\r\n \r\n export const api = {\r\n@@ -84,9 +84,9 @@\n       cache.clear();\r\n \r\n       return result as T;\r\n     } catch (err) {\r\n-      logger.error(`Failed to create ${path}`, 'api.post', err);\r\n+      logger.error(`Failed to create ${path}`, { source: 'api.post', error: err });\r\n       throw new APIError(`Failed to create ${path}`, 500);\r\n     }\r\n \r\n   },\r\n"
                },
                {
                    "date": 1740852812378,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -0,0 +1,156 @@\n+import { supabase } from './supabase';\r\n+import { logger } from './logger';\r\n+import { DataCache } from './cache';\r\n+import { dataFlowMonitor } from './monitoring/instance';\r\n+\r\n+export class APIError extends Error {\r\n+  constructor(message: string, public statusCode: number) {\r\n+    super(message);\r\n+    this.name = 'APIError';\r\n+  }\r\n+}\r\n+\r\n+const cache = DataCache.getInstance();\r\n+\r\n+const handleQueryError = (error: any, path: string) => {\r\n+  logger.error(`Failed to fetch ${path}: ${error}`, { source: 'api.get' } );\r\n+  throw new APIError(`Failed to fetch ${path}`, 500);\r\n+};\r\n+\r\n+export const api = {\r\n+  async get<T>(path: string, options: { where?: any; include?: any; orderBy?: any } = {}): Promise<T[]> {\r\n+    const loadId = `GET_${path}_${Date.now()}`;\r\n+    await dataFlowMonitor.trackDataLoad(loadId, { \r\n+      source: path,\r\n+      recordCount: 0 // Will be updated when data is received\r\n+    });\r\n+    const cacheKey = `${path}-${JSON.stringify(options)}`;\r\n+    \r\n+    const opId = dataFlowMonitor.startOperation('query', `GET ${path}`, { options });\r\n+    try {\r\n+      // Try cache first\r\n+      const cachedData = cache.get(cacheKey);\r\n+      if (cachedData) {\r\n+        dataFlowMonitor.endOperation(opId);\r\n+        return cachedData;\r\n+      }\r\n+\r\n+      const query = supabase\r\n+        .from(path);\r\n+\r\n+      let selection = query.select(options.include ? `*, ${options.include}` : '*');\r\n+\r\n+      if (options.where) {\r\n+        Object.entries(options.where).forEach(([key, value]) => {\r\n+          if (value !== undefined && value !== null) {\r\n+            selection = selection.eq(key, value);\r\n+          }\r\n+        });\r\n+      }\r\n+\r\n+      if (options.orderBy) {\r\n+        Object.entries(options.orderBy).forEach(([key, value]) => {\r\n+          selection = selection.order(key, { ascending: value === 'asc' });\r\n+        });\r\n+      }\r\n+\r\n+      const { data, error } = await selection;\r\n+      \r\n+      if (error) throw error;\r\n+      \r\n+      // Cache successful response\r\n+      if (data) {\r\n+        cache.set(cacheKey, data);\r\n+      }\r\n+      dataFlowMonitor.endOperation(opId);\r\n+      \r\n+      return ( data ||[]) as T[];\r\n+    } catch (err) {\r\n+      return handleQueryError(err, path);\r\n+    }\r\n+  },\r\n+\r\n+  async post<T>(path: string, data: any): Promise<T> {\r\n+    try {\r\n+      const { data: result, error } = await supabase\r\n+        .from(path)\r\n+        .insert(data)\r\n+        .select()\r\n+        .single();\r\n+\r\n+      if (error) throw error;\r\n+\r\n+      // Invalidate relevant cache entries\r\n+      cache.clear();\r\n+\r\n+      return result as T;\r\n+    } catch (err) {\r\n+      logger.error(`Failed to create ${path}`, { source: 'api.post', error: err });\r\n+      throw new APIError(`Failed to create ${path}`, 500);\r\n+    }\r\n+\r\n+  },\r\n+\r\n+  async put<T>(path: string, id: string, data: any): Promise<T> {\r\n+    try {\r\n+      const { data: result, error } = await supabase\r\n+        .from(path)\r\n+        .update(data)\r\n+        .eq('id', id)\r\n+        .select()\r\n+        .single();\r\n+\r\n+      if (error) throw error;\r\n+\r\n+      // Invalidate relevant cache entries\r\n+      cache.clear();\r\n+\r\n+      return result as T;\r\n+    } catch (err) {\r\n+      logger.error(`Failed to update ${path}`, { source: 'api.put', error: err });\r\n+      throw new APIError(`Failed to update ${path}`, 500);\r\n+    }\r\n+\r\n+  },\r\n+\r\n+  async delete(path: string, id: string): Promise<boolean> {\r\n+    try {\r\n+      const { error } = await supabase\r\n+        .from(path)\r\n+        .delete()\r\n+        .eq('id', id);\r\n+\r\n+      if (error) throw error;\r\n+\r\n+      // Invalidate relevant cache entries\r\n+      cache.clear();\r\n+\r\n+      return true;\r\n+    } catch (err) {\r\n+      logger.error(`Failed to delete ${path}`, { source: 'api.delete', error: err });\r\n+      throw new APIError(`Failed to delete ${path}`, 500);\r\n+\r\n+    }\r\n+  },\r\n+\r\n+  // Batch operations with transaction support\r\n+  async batch<T>(operations: (() => Promise<T>)[]): Promise<T[]> {\r\n+    try {\r\n+      const results = await Promise.allSettled(operations.map(op => op()));\r\n+      \r\n+      const failures = results.filter(r => r.status === 'rejected');\r\n+      if (failures.length > 0) {\r\n+        logger.error('Batch operation partially failed', { source: 'api.batch', error: failures });\r\n+\r\n+      }\r\n+\r\n+      return results\r\n+        .filter((r): r is PromiseFulfilledResult<Awaited<T>> => r.status === 'fulfilled')\r\n+        .map(r => r.value);\r\n+    } catch (err) {\r\n+      logger.error('Batch operation failed', 'api.batch', err);\r\n+      throw new APIError('Batch operation failed', 500);\r\n+\r\n+    }\r\n+  }\r\n+};\n\\ No newline at end of file\n"
                },
                {
                    "date": 1740852835165,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,14 +25,12 @@\n       recordCount: 0 // Will be updated when data is received\r\n     });\r\n     const cacheKey = `${path}-${JSON.stringify(options)}`;\r\n     \r\n-    const opId = dataFlowMonitor.startOperation('query', `GET ${path}`, { options });\r\n     try {\r\n       // Try cache first\r\n-      const cachedData = cache.get(cacheKey);\r\n+      const cachedData = cache.get<T[]>(cacheKey);\r\n       if (cachedData) {\r\n-        dataFlowMonitor.endOperation(opId);\r\n         return cachedData;\r\n       }\r\n \r\n       const query = supabase\r\n@@ -61,11 +59,10 @@\n       // Cache successful response\r\n       if (data) {\r\n         cache.set(cacheKey, data);\r\n       }\r\n-      dataFlowMonitor.endOperation(opId);\r\n       \r\n-      return ( data ||[]) as T[];\r\n+      return (data || []) as T[];\r\n     } catch (err) {\r\n       return handleQueryError(err, path);\r\n     }\r\n   },\r\n@@ -147,166 +144,10 @@\n       return results\r\n         .filter((r): r is PromiseFulfilledResult<Awaited<T>> => r.status === 'fulfilled')\r\n         .map(r => r.value);\r\n     } catch (err) {\r\n-      logger.error('Batch operation failed', 'api.batch', err);\r\n+      logger.error('Batch operation failed', { source: 'api.batch', error: err });\r\n       throw new APIError('Batch operation failed', 500);\r\n \r\n     }\r\n   }\r\n-};\n-import { supabase } from './supabase';\r\n-import { logger } from './logger';\r\n-import { DataCache } from './cache';\r\n-import { dataFlowMonitor } from './monitoring/instance';\r\n-\r\n-export class APIError extends Error {\r\n-  constructor(message: string, public statusCode: number) {\r\n-    super(message);\r\n-    this.name = 'APIError';\r\n-  }\r\n-}\r\n-\r\n-const cache = DataCache.getInstance();\r\n-\r\n-const handleQueryError = (error: any, path: string) => {\r\n-  logger.error(`Failed to fetch ${path}: ${error}`, { source: 'api.get' } );\r\n-  throw new APIError(`Failed to fetch ${path}`, 500);\r\n-};\r\n-\r\n-export const api = {\r\n-  async get<T>(path: string, options: { where?: any; include?: any; orderBy?: any } = {}): Promise<T[]> {\r\n-    const loadId = `GET_${path}_${Date.now()}`;\r\n-    await dataFlowMonitor.trackDataLoad(loadId, { \r\n-      source: path,\r\n-      recordCount: 0 // Will be updated when data is received\r\n-    });\r\n-    const cacheKey = `${path}-${JSON.stringify(options)}`;\r\n-    \r\n-    const opId = dataFlowMonitor.startOperation('query', `GET ${path}`, { options });\r\n-    try {\r\n-      // Try cache first\r\n-      const cachedData = cache.get(cacheKey);\r\n-      if (cachedData) {\r\n-        dataFlowMonitor.endOperation(opId);\r\n-        return cachedData;\r\n-      }\r\n-\r\n-      const query = supabase\r\n-        .from(path);\r\n-\r\n-      let selection = query.select(options.include ? `*, ${options.include}` : '*');\r\n-\r\n-      if (options.where) {\r\n-        Object.entries(options.where).forEach(([key, value]) => {\r\n-          if (value !== undefined && value !== null) {\r\n-            selection = selection.eq(key, value);\r\n-          }\r\n-        });\r\n-      }\r\n-\r\n-      if (options.orderBy) {\r\n-        Object.entries(options.orderBy).forEach(([key, value]) => {\r\n-          selection = selection.order(key, { ascending: value === 'asc' });\r\n-        });\r\n-      }\r\n-\r\n-      const { data, error } = await selection;\r\n-      \r\n-      if (error) throw error;\r\n-      \r\n-      // Cache successful response\r\n-      if (data) {\r\n-        cache.set(cacheKey, data);\r\n-      }\r\n-      dataFlowMonitor.endOperation(opId);\r\n-      \r\n-      return ( data ||[]) as T[];\r\n-    } catch (err) {\r\n-      return handleQueryError(err, path);\r\n-    }\r\n-  },\r\n-\r\n-  async post<T>(path: string, data: any): Promise<T> {\r\n-    try {\r\n-      const { data: result, error } = await supabase\r\n-        .from(path)\r\n-        .insert(data)\r\n-        .select()\r\n-        .single();\r\n-\r\n-      if (error) throw error;\r\n-\r\n-      // Invalidate relevant cache entries\r\n-      cache.clear();\r\n-\r\n-      return result as T;\r\n-    } catch (err) {\r\n-      logger.error(`Failed to create ${path}`, { source: 'api.post', error: err });\r\n-      throw new APIError(`Failed to create ${path}`, 500);\r\n-    }\r\n-\r\n-  },\r\n-\r\n-  async put<T>(path: string, id: string, data: any): Promise<T> {\r\n-    try {\r\n-      const { data: result, error } = await supabase\r\n-        .from(path)\r\n-        .update(data)\r\n-        .eq('id', id)\r\n-        .select()\r\n-        .single();\r\n-\r\n-      if (error) throw error;\r\n-\r\n-      // Invalidate relevant cache entries\r\n-      cache.clear();\r\n-\r\n-      return result as T;\r\n-    } catch (err) {\r\n-      logger.error(`Failed to update ${path}`, 'api.put', err);\r\n-      throw new APIError(`Failed to update ${path}`, 500);\r\n-    }\r\n-\r\n-  },\r\n-\r\n-  async delete(path: string, id: string): Promise<boolean> {\r\n-    try {\r\n-      const { error } = await supabase\r\n-        .from(path)\r\n-        .delete()\r\n-        .eq('id', id);\r\n-\r\n-      if (error) throw error;\r\n-\r\n-      // Invalidate relevant cache entries\r\n-      cache.clear();\r\n-\r\n-      return true;\r\n-    } catch (err) {\r\n-      logger.error(`Failed to delete ${path}`, 'api.delete', err);\r\n-      throw new APIError(`Failed to delete ${path}`, 500);\r\n-\r\n-    }\r\n-  },\r\n-\r\n-  // Batch operations with transaction support\r\n-  async batch<T>(operations: (() => Promise<T>)[]): Promise<T[]> {\r\n-    try {\r\n-      const results = await Promise.allSettled(operations.map(op => op()));\r\n-      \r\n-      const failures = results.filter(r => r.status === 'rejected');\r\n-      if (failures.length > 0) {\r\n-        logger.error('Batch operation partially failed', 'api.batch', failures);\r\n-\r\n-      }\r\n-\r\n-      return results\r\n-        .filter((r): r is PromiseFulfilledResult<Awaited<T>> => r.status === 'fulfilled')\r\n-        .map(r => r.value);\r\n-    } catch (err) {\r\n-      logger.error('Batch operation failed', 'api.batch', err);\r\n-      throw new APIError('Batch operation failed', 500);\r\n-\r\n-    }\r\n-  }\r\n };\n\\ No newline at end of file\n"
                },
                {
                    "date": 1740852863472,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -27,9 +27,9 @@\n     const cacheKey = `${path}-${JSON.stringify(options)}`;\r\n     \r\n     try {\r\n       // Try cache first\r\n-      const cachedData = cache.get<T[]>(cacheKey);\r\n+      const cachedData = cache.get(cacheKey) as T[] | null;\r\n       if (cachedData) {\r\n         return cachedData;\r\n       }\r\n \r\n"
                }
            ],
            "date": 1739013790585,
            "name": "Commit-0",
            "content": "import { supabase } from './supabase';\r\nimport { logger } from './logger';\r\nimport { DataCache } from './cache';\r\nimport { dataFlowMonitor } from './monitoring/instance';\r\n\r\nexport class APIError extends Error {\r\n  constructor(message: string, public statusCode: number) {\r\n    super(message);\r\n    this.name = 'APIError';\r\n  }\r\n}\r\n\r\nconst cache = DataCache.getInstance();\r\n\r\nconst handleQueryError = (error: any, path: string) => {\r\n  logger.error(`Failed to fetch ${path}: ${error}`, 'api.get');\r\n  throw new APIError(`Failed to fetch ${path}`, 500);\r\n};\r\n\r\nexport const api = {\r\n  async get<T>(path: string, options: { where?: any; include?: any; orderBy?: any } = {}): Promise<T[]> {\r\n    const loadId = `GET_${path}_${Date.now()}`;\r\n    const cacheKey = `${path}-${JSON.stringify(options)}`;\r\n    \r\n    const opId = dataFlowMonitor.startOperation('query', `GET ${path}`, { options });\r\n    try {\r\n      // Try cache first\r\n      const cachedData = cache.get(cacheKey);\r\n      if (cachedData) {\r\n        dataFlowMonitor.endOperation(opId);\r\n        return cachedData;\r\n      }\r\n\r\n      const query = supabase\r\n        .from(path);\r\n\r\n      let selection = query.select(options.include ? `*, ${options.include}` : '*');\r\n\r\n      if (options.where) {\r\n        Object.entries(options.where).forEach(([key, value]) => {\r\n          if (value !== undefined && value !== null) {\r\n            selection = selection.eq(key, value);\r\n          }\r\n        });\r\n      }\r\n\r\n      if (options.orderBy) {\r\n        Object.entries(options.orderBy).forEach(([key, value]) => {\r\n          selection = selection.order(key, { ascending: value === 'asc' });\r\n        });\r\n      }\r\n\r\n      const { data, error } = await selection;\r\n      \r\n      if (error) throw error;\r\n      \r\n      // Cache successful response\r\n      if (data) {\r\n        cache.set(cacheKey, data);\r\n      }\r\n      dataFlowMonitor.endOperation(opId);\r\n      \r\n      return ( data ||[]) as T[];\r\n    } catch (err) {\r\n      return handleQueryError(err, path);\r\n    }\r\n  },\r\n\r\n  async post<T>(path: string, data: any): Promise<T> {\r\n    try {\r\n      const { data: result, error } = await supabase\r\n        .from(path)\r\n        .insert(data)\r\n        .select()\r\n        .single();\r\n\r\n      if (error) throw error;\r\n\r\n      // Invalidate relevant cache entries\r\n      cache.clear();\r\n\r\n      return result as T;\r\n    } catch (err) {\r\n      logger.error(`Failed to create ${path}`, {\r\n        context: { error: err, data },\r\n        source: 'api.post'\r\n      });\r\n      throw new APIError(`Failed to create ${path}`, 500);\r\n    }\r\n  },\r\n\r\n  async put<T>(path: string, id: string, data: any): Promise<T> {\r\n    try {\r\n      const { data: result, error } = await supabase\r\n        .from(path)\r\n        .update(data)\r\n        .eq('id', id)\r\n        .select()\r\n        .single();\r\n\r\n      if (error) throw error;\r\n\r\n      // Invalidate relevant cache entries\r\n      cache.clear();\r\n\r\n      return result as T;\r\n    } catch (err) {\r\n      logger.error(`Failed to update ${path}`, {\r\n        context: { error: err, id, data },\r\n        source: 'api.put'\r\n      });\r\n      throw new APIError(`Failed to update ${path}`, 500);\r\n    }\r\n  },\r\n\r\n  async delete(path: string, id: string): Promise<boolean> {\r\n    try {\r\n      const { error } = await supabase\r\n        .from(path)\r\n        .delete()\r\n        .eq('id', id);\r\n\r\n      if (error) throw error;\r\n\r\n      // Invalidate relevant cache entries\r\n      cache.clear();\r\n\r\n      return true;\r\n    } catch (err) {\r\n      logger.error(`Failed to delete ${path}`, {\r\n        context: { error: err, id },\r\n        source: 'api.delete'\r\n      });\r\n      throw new APIError(`Failed to delete ${path}`, 500);\r\n    }\r\n  },\r\n\r\n  // Batch operations with transaction support\r\n  async batch<T>(operations: (() => Promise<T>)[]): Promise<T[]> {\r\n    try {\r\n      const results = await Promise.allSettled(operations.map(op => op()));\r\n      \r\n      const failures = results.filter(r => r.status === 'rejected');\r\n      if (failures.length > 0) {\r\n        logger.error('Batch operation partially failed', {\r\n          context: { failures },\r\n          source: 'api.batch'\r\n        });\r\n      }\r\n\r\n      return results\r\n        .filter((r): r is PromiseFulfilledResult<Awaited<T>> => r.status === 'fulfilled')\r\n        .map(r => r.value);\r\n    } catch (err) {\r\n      logger.error('Batch operation failed', {\r\n        context: { error: err },\r\n        source: 'api.batch'\r\n      });\r\n      throw new APIError('Batch operation failed', 500);\r\n    }\r\n  }\r\n};"
        }
    ]
}