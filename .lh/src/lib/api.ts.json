{
    "sourceFile": "src/lib/api.ts",
    "activeCommit": 0,
    "commits": [
        {
            "activePatchIndex": 6,
            "patches": [
                {
                    "date": 1739013790585,
                    "content": "Index: \n===================================================================\n--- \n+++ \n"
                },
                {
                    "date": 1739013841137,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -19,8 +19,12 @@\n \r\n export const api = {\r\n   async get<T>(path: string, options: { where?: any; include?: any; orderBy?: any } = {}): Promise<T[]> {\r\n     const loadId = `GET_${path}_${Date.now()}`;\r\n+    await dataFlowMonitor.trackDataLoad(loadId, { \r\n+      source: path,\r\n+      recordCount: 0 // Will be updated when data is received\r\n+    });\r\n     const cacheKey = `${path}-${JSON.stringify(options)}`;\r\n     \r\n     const opId = dataFlowMonitor.startOperation('query', `GET ${path}`, { options });\r\n     try {\r\n"
                },
                {
                    "date": 1739013877586,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,14 +25,12 @@\n       recordCount: 0 // Will be updated when data is received\r\n     });\r\n     const cacheKey = `${path}-${JSON.stringify(options)}`;\r\n     \r\n-    const opId = dataFlowMonitor.startOperation('query', `GET ${path}`, { options });\r\n     try {\r\n       // Try cache first\r\n       const cachedData = cache.get(cacheKey);\r\n       if (cachedData) {\r\n-        dataFlowMonitor.endOperation(opId);\r\n         return cachedData;\r\n       }\r\n \r\n       const query = supabase\r\n"
                },
                {
                    "date": 1739013883872,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -25,12 +25,14 @@\n       recordCount: 0 // Will be updated when data is received\r\n     });\r\n     const cacheKey = `${path}-${JSON.stringify(options)}`;\r\n     \r\n+    const opId = dataFlowMonitor.startOperation('query', `GET ${path}`, { options });\r\n     try {\r\n       // Try cache first\r\n       const cachedData = cache.get(cacheKey);\r\n       if (cachedData) {\r\n+        dataFlowMonitor.endOperation(opId);\r\n         return cachedData;\r\n       }\r\n \r\n       const query = supabase\r\n"
                },
                {
                    "date": 1739014323580,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n import { supabase } from './supabase';\r\n import { logger } from './logger';\r\n import { DataCache } from './cache';\r\n-import { dataFlowMonitor } from './monitoring/instance';\r\n+import { dataFlowMonitor } from './monitoring/DataFlowMonitor';\r\n \r\n export class APIError extends Error {\r\n   constructor(message: string, public statusCode: number) {\r\n     super(message);\r\n"
                },
                {
                    "date": 1739015150901,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -1,8 +1,8 @@\n import { supabase } from './supabase';\r\n import { logger } from './logger';\r\n import { DataCache } from './cache';\r\n-import { dataFlowMonitor } from './monitoring/DataFlowMonitor';\r\n+import { dataFlowMonitor } from './monitoring/instance';\r\n \r\n export class APIError extends Error {\r\n   constructor(message: string, public statusCode: number) {\r\n     super(message);\r\n"
                },
                {
                    "date": 1739015183755,
                    "content": "Index: \n===================================================================\n--- \n+++ \n@@ -84,14 +84,12 @@\n       cache.clear();\r\n \r\n       return result as T;\r\n     } catch (err) {\r\n-      logger.error(`Failed to create ${path}`, {\r\n-        context: { error: err, data },\r\n-        source: 'api.post'\r\n-      });\r\n+      logger.error(`Failed to create ${path}`, 'api.post', err);\r\n       throw new APIError(`Failed to create ${path}`, 500);\r\n     }\r\n+\r\n   },\r\n \r\n   async put<T>(path: string, id: string, data: any): Promise<T> {\r\n     try {\r\n@@ -108,14 +106,12 @@\n       cache.clear();\r\n \r\n       return result as T;\r\n     } catch (err) {\r\n-      logger.error(`Failed to update ${path}`, {\r\n-        context: { error: err, id, data },\r\n-        source: 'api.put'\r\n-      });\r\n+      logger.error(`Failed to update ${path}`, 'api.put', err);\r\n       throw new APIError(`Failed to update ${path}`, 500);\r\n     }\r\n+\r\n   },\r\n \r\n   async delete(path: string, id: string): Promise<boolean> {\r\n     try {\r\n@@ -130,13 +126,11 @@\n       cache.clear();\r\n \r\n       return true;\r\n     } catch (err) {\r\n-      logger.error(`Failed to delete ${path}`, {\r\n-        context: { error: err, id },\r\n-        source: 'api.delete'\r\n-      });\r\n+      logger.error(`Failed to delete ${path}`, 'api.delete', err);\r\n       throw new APIError(`Failed to delete ${path}`, 500);\r\n+\r\n     }\r\n   },\r\n \r\n   // Batch operations with transaction support\r\n@@ -145,22 +139,18 @@\n       const results = await Promise.allSettled(operations.map(op => op()));\r\n       \r\n       const failures = results.filter(r => r.status === 'rejected');\r\n       if (failures.length > 0) {\r\n-        logger.error('Batch operation partially failed', {\r\n-          context: { failures },\r\n-          source: 'api.batch'\r\n-        });\r\n+        logger.error('Batch operation partially failed', 'api.batch', failures);\r\n+\r\n       }\r\n \r\n       return results\r\n         .filter((r): r is PromiseFulfilledResult<Awaited<T>> => r.status === 'fulfilled')\r\n         .map(r => r.value);\r\n     } catch (err) {\r\n-      logger.error('Batch operation failed', {\r\n-        context: { error: err },\r\n-        source: 'api.batch'\r\n-      });\r\n+      logger.error('Batch operation failed', 'api.batch', err);\r\n       throw new APIError('Batch operation failed', 500);\r\n+\r\n     }\r\n   }\r\n };\n\\ No newline at end of file\n"
                }
            ],
            "date": 1739013790585,
            "name": "Commit-0",
            "content": "import { supabase } from './supabase';\r\nimport { logger } from './logger';\r\nimport { DataCache } from './cache';\r\nimport { dataFlowMonitor } from './monitoring/instance';\r\n\r\nexport class APIError extends Error {\r\n  constructor(message: string, public statusCode: number) {\r\n    super(message);\r\n    this.name = 'APIError';\r\n  }\r\n}\r\n\r\nconst cache = DataCache.getInstance();\r\n\r\nconst handleQueryError = (error: any, path: string) => {\r\n  logger.error(`Failed to fetch ${path}: ${error}`, 'api.get');\r\n  throw new APIError(`Failed to fetch ${path}`, 500);\r\n};\r\n\r\nexport const api = {\r\n  async get<T>(path: string, options: { where?: any; include?: any; orderBy?: any } = {}): Promise<T[]> {\r\n    const loadId = `GET_${path}_${Date.now()}`;\r\n    const cacheKey = `${path}-${JSON.stringify(options)}`;\r\n    \r\n    const opId = dataFlowMonitor.startOperation('query', `GET ${path}`, { options });\r\n    try {\r\n      // Try cache first\r\n      const cachedData = cache.get(cacheKey);\r\n      if (cachedData) {\r\n        dataFlowMonitor.endOperation(opId);\r\n        return cachedData;\r\n      }\r\n\r\n      const query = supabase\r\n        .from(path);\r\n\r\n      let selection = query.select(options.include ? `*, ${options.include}` : '*');\r\n\r\n      if (options.where) {\r\n        Object.entries(options.where).forEach(([key, value]) => {\r\n          if (value !== undefined && value !== null) {\r\n            selection = selection.eq(key, value);\r\n          }\r\n        });\r\n      }\r\n\r\n      if (options.orderBy) {\r\n        Object.entries(options.orderBy).forEach(([key, value]) => {\r\n          selection = selection.order(key, { ascending: value === 'asc' });\r\n        });\r\n      }\r\n\r\n      const { data, error } = await selection;\r\n      \r\n      if (error) throw error;\r\n      \r\n      // Cache successful response\r\n      if (data) {\r\n        cache.set(cacheKey, data);\r\n      }\r\n      dataFlowMonitor.endOperation(opId);\r\n      \r\n      return ( data ||[]) as T[];\r\n    } catch (err) {\r\n      return handleQueryError(err, path);\r\n    }\r\n  },\r\n\r\n  async post<T>(path: string, data: any): Promise<T> {\r\n    try {\r\n      const { data: result, error } = await supabase\r\n        .from(path)\r\n        .insert(data)\r\n        .select()\r\n        .single();\r\n\r\n      if (error) throw error;\r\n\r\n      // Invalidate relevant cache entries\r\n      cache.clear();\r\n\r\n      return result as T;\r\n    } catch (err) {\r\n      logger.error(`Failed to create ${path}`, {\r\n        context: { error: err, data },\r\n        source: 'api.post'\r\n      });\r\n      throw new APIError(`Failed to create ${path}`, 500);\r\n    }\r\n  },\r\n\r\n  async put<T>(path: string, id: string, data: any): Promise<T> {\r\n    try {\r\n      const { data: result, error } = await supabase\r\n        .from(path)\r\n        .update(data)\r\n        .eq('id', id)\r\n        .select()\r\n        .single();\r\n\r\n      if (error) throw error;\r\n\r\n      // Invalidate relevant cache entries\r\n      cache.clear();\r\n\r\n      return result as T;\r\n    } catch (err) {\r\n      logger.error(`Failed to update ${path}`, {\r\n        context: { error: err, id, data },\r\n        source: 'api.put'\r\n      });\r\n      throw new APIError(`Failed to update ${path}`, 500);\r\n    }\r\n  },\r\n\r\n  async delete(path: string, id: string): Promise<boolean> {\r\n    try {\r\n      const { error } = await supabase\r\n        .from(path)\r\n        .delete()\r\n        .eq('id', id);\r\n\r\n      if (error) throw error;\r\n\r\n      // Invalidate relevant cache entries\r\n      cache.clear();\r\n\r\n      return true;\r\n    } catch (err) {\r\n      logger.error(`Failed to delete ${path}`, {\r\n        context: { error: err, id },\r\n        source: 'api.delete'\r\n      });\r\n      throw new APIError(`Failed to delete ${path}`, 500);\r\n    }\r\n  },\r\n\r\n  // Batch operations with transaction support\r\n  async batch<T>(operations: (() => Promise<T>)[]): Promise<T[]> {\r\n    try {\r\n      const results = await Promise.allSettled(operations.map(op => op()));\r\n      \r\n      const failures = results.filter(r => r.status === 'rejected');\r\n      if (failures.length > 0) {\r\n        logger.error('Batch operation partially failed', {\r\n          context: { failures },\r\n          source: 'api.batch'\r\n        });\r\n      }\r\n\r\n      return results\r\n        .filter((r): r is PromiseFulfilledResult<Awaited<T>> => r.status === 'fulfilled')\r\n        .map(r => r.value);\r\n    } catch (err) {\r\n      logger.error('Batch operation failed', {\r\n        context: { error: err },\r\n        source: 'api.batch'\r\n      });\r\n      throw new APIError('Batch operation failed', 500);\r\n    }\r\n  }\r\n};"
        }
    ]
}